{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import sys\n",
    "import math\n",
    "import heapq\n",
    "import shutil\n",
    "import queue as Q\n",
    "from nltk.stem import PorterStemmer \n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import jieba\n",
    "import nltk\n",
    "from model import TrieNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = os.path.exists('blocks')\n",
    "if not folder:\n",
    "    os.makedirs('blocks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_path = '动漫'\n",
    "files= os.listdir(ori_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct(intToJuji, intToFanju):\n",
    "    i = 0\n",
    "    j = -1000\n",
    "    k = 0\n",
    "    terms_id = dict()\n",
    "    for root, dirs, files in os.walk(ori_path, topdown=True):\n",
    "        if '\\.ipynb_checkpoints' in root:\n",
    "            continue\n",
    "        if len(files) == 0:\n",
    "            j+=1000\n",
    "            i=0\n",
    "            intToFanju[j] = root\n",
    "        else:\n",
    "            i+=1\n",
    "            key = j+i\n",
    "            intToJuji[key] = root\n",
    "            for name in files:\n",
    "                f = open(root+\"\\\\\"+ name, errors='ignore')\n",
    "                lines = f.readlines()\n",
    "                texts_s,texts_l = arrayTodict(lines)\n",
    "                counts = cut3(texts_s)\n",
    "            for word in counts:\n",
    "                terms_id[word] = terms_id.get(word, 0) + counts[word]\n",
    "            #if (sys.getsizeof(terms_id) > 10000000):\n",
    "             #   for key_word in terms_id:\n",
    "              #      jieba.add_word(key_word, freq = 100*terms_id[key_word], tag = None)\n",
    "               # terms_id = dict()\n",
    "    return terms_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct(intToJuji, intToFanju):\n",
    "    i = 0\n",
    "    j = -1000\n",
    "    k = 0\n",
    "    terms_id = dict()\n",
    "    for root, dirs, files in os.walk(ori_path, topdown=True):\n",
    "        if '\\.ipynb_checkpoints' in root:\n",
    "            continue\n",
    "        if len(files) == 0:\n",
    "            j+=1000\n",
    "            i=0\n",
    "            intToFanju[j] = root\n",
    "        else:\n",
    "            i+=1\n",
    "            key = j+i\n",
    "            intToJuji[key] = root\n",
    "            for name in files:\n",
    "                f = open(root+\"\\\\\"+ name, errors='ignore')\n",
    "                lines = f.readlines()\n",
    "                texts_s,texts_l = arrayTodict(lines)\n",
    "                counts = cut3(texts_s)\n",
    "            for word in counts:\n",
    "                terms_id[word] = terms_id.get(word, 0) + counts[word]\n",
    "            if (sys.getsizeof(terms_id) > 10000000):\n",
    "                for key_word in terms_id:\n",
    "                    jieba.add_word(key_word, freq = 100*terms_id[key_word], tag = None)\n",
    "                    print(key_word,100*terms_id[key_word] )\n",
    "                terms_id = dict()\n",
    "    for root, dirs, files in os.walk(ori_path, topdown=True):\n",
    "        if '\\.ipynb_checkpoints' in root:\n",
    "            continue\n",
    "        if len(files) == 0:\n",
    "            j+=1000\n",
    "            i=0\n",
    "            intToFanju[j] = root\n",
    "        else:\n",
    "            i+=1\n",
    "            key = j+i\n",
    "            intToJuji[key] = root\n",
    "            for name in files:\n",
    "                f = open(root+\"\\\\\"+ name, errors='ignore')\n",
    "                lines = f.readlines()\n",
    "                texts_s,texts_l = arrayTodict(lines)\n",
    "                counts = cut3(texts_s)\n",
    "                for word in counts:\n",
    "                    if word in terms_id:\n",
    "                        terms_id[word].append((key,counts[word]))\n",
    "                    else: \n",
    "                        terms_id[word] = [(key,counts[word])]\n",
    "                if (sys.getsizeof(terms_id) > 1000000):\n",
    "                    k += 1\n",
    "                    build_c(k, terms_id)\n",
    "                    terms_id = dict()\n",
    "    build_c(k+1, terms_id)\n",
    "    terms_id = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "intToJuji = dict()\n",
    "intToFanju= dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_words = construct(intToJuji, intToFanju)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_words = sorted(small_words.items(),key = lambda item: -item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2031105"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(small_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_words = []\n",
    "for word in small_words:\n",
    "    if word[1]!=1:\n",
    "        new_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18280056"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(small_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'sjkk啥呀'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "586155"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"new_words_all.txt\"\n",
    "with open(path, 'w', newline='') as f:\n",
    "    for key in new_words:\n",
    "        f.write(''+key[0])\n",
    "        f.write(',')\n",
    "        f.write(str(key[1]))\n",
    "        f.write('\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in superfluous:\n",
    "    s = s.rstrip(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sjkk'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shorten(s):\n",
    "    superfluous = ' 啊吧哇呀嘛吗耶？！?!.。诶了阿哈呗啥'\n",
    "    for i in superfluous:\n",
    "        s = s.rstrip(i)\n",
    "    ss= ''.join(reversed(s))\n",
    "    k = -1\n",
    "    j = 0\n",
    "    array = [-1]\n",
    "    plen = len(ss)\n",
    "    zeros = 0\n",
    "    nonze = 0\n",
    "    while j < plen:\n",
    "        if k == -1 or ss[j] == ss[k]:\n",
    "            k += 1\n",
    "            j += 1\n",
    "            if k == 0:\n",
    "                if j != zeros + 1:\n",
    "                    loop = (int)(nonze/zeros) -1\n",
    "                    return cut_string(s, plen) if loop<1 else cut_string(s, plen - zeros*loop)\n",
    "                zeros += 1\n",
    "            else:\n",
    "                nonze += 1\n",
    "            array.append(k)\n",
    "        else:\n",
    "            k = array[k]\n",
    "    return cut_string(s, plen) if zeros==plen else (cut_string(s, zeros) if zeros>1 else cut_string(s, zeros+1)) \n",
    "def cut_string(s, lens):\n",
    "    return s[0: lens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrayTodict(lines):\n",
    "    word_dict_s={}\n",
    "    word_dict_l={}\n",
    "    for line in lines:\n",
    "        line=shorten(line.strip('\\n').replace(' ', ''))\n",
    "        if len(line)<2:\n",
    "            continue\n",
    "        if len(line)<5:\n",
    "            if word_dict_s.get(line):\n",
    "                word_dict_s[line] += 1\n",
    "            else:\n",
    "                word_dict_s[line] = 1\n",
    "            continue\n",
    "        if word_dict_l.get(line):\n",
    "            word_dict_l[line] += 1\n",
    "        else:\n",
    "            word_dict_l[line] = 1\n",
    "    return word_dict_s, word_dict_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut1(word_dict):\n",
    "    counts = dict()\n",
    "    for line in word_dict:\n",
    "        num = word_dict[line]\n",
    "        words = jieba.lcut(line)\n",
    "        for word in words:\n",
    "            if len(word) == 1:\n",
    "                continue\n",
    "            else:\n",
    "                counts[word] = counts.get(word, 0) + num\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut3(word_dict):\n",
    "    counts = dict()\n",
    "    for line in word_dict:\n",
    "        num = word_dict[line]\n",
    "        counts[line] = counts.get(line, 0) + num\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut2(word_dict):\n",
    "    counts = dict()\n",
    "    for line in word_dict:\n",
    "        num = word_dict[line]\n",
    "        if len(line)<5:\n",
    "            counts[line] = counts.get(line, 0) + num\n",
    "            continue\n",
    "        words = jieba.lcut(line)\n",
    "        for word in words:\n",
    "            if len(word) == 1:\n",
    "                continue\n",
    "            else:\n",
    "                counts[word] = counts.get(word, 0) + num\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_c(i, terms_id):\n",
    "    list1 = []\n",
    "    path = \"chunks/chunk_\"+str(i)+\".txt\"\n",
    "    list1 = sorted(terms_id.items(), key=lambda item: item[0])\n",
    "    with open(path, 'w', newline='') as f:\n",
    "        for key in list1:\n",
    "            list2= []\n",
    "            f.write(str(key[0]))\n",
    "            for word in key[1]:\n",
    "                f.write(',')\n",
    "                f.write(str(word[0]))\n",
    "                f.write('-')\n",
    "                f.write(str(word[1]))\n",
    "            f.write('\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dirs():\n",
    "    # Create a new folder to generate inverted indexes\n",
    "    folder1 = os.path.exists('chunks')\n",
    "    folder2 = os.path.exists('blocks')\n",
    "    if not folder1:\n",
    "        os.makedirs('chunks')\n",
    "    if not folder2:\n",
    "        os.makedirs('blocks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_dirs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'233'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shorten('2333')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'233'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shorten('23333333')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class treeNode:\n",
    "    def __init__(self, nameValue, numOccur, parentNode):\n",
    "        self.name = nameValue\n",
    "        self.count = numOccur\n",
    "        self.nodeLink = None\n",
    "        self.parent = parentNode\n",
    "        self.children = {}\n",
    "\n",
    "    def inc(self, numOccur):\n",
    "        self.count += numOccur\n",
    "\n",
    "    def disp(self, ind=1):\n",
    "        print ('  '*ind, self.name, ' ', self.count)\n",
    "        for child in self.children.values():\n",
    "            child.disp(ind+1)\n",
    "    def disp_plus(self, ind=1):\n",
    "        print ('  '*ind, self.name, ' ', self.count)\n",
    "        for child in self.children.values():\n",
    "            if child.count > 10:\n",
    "                child.disp_plus(ind+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateHeader(nodeToTest, targetNode):\n",
    "    while nodeToTest.nodeLink != None:\n",
    "        nodeToTest = nodeToTest.nodeLink\n",
    "    nodeToTest.nodeLink = targetNode\n",
    "def updateFPtree(items, inTree, headerTable, count):\n",
    "    if items[0] in inTree.children:\n",
    "        # 判断items的第一个结点是否已作为子结点\n",
    "        inTree.children[items[0]].inc(count)\n",
    "    else:\n",
    "        # 创建新的分支\n",
    "        inTree.children[items[0]] = treeNode(items[0], count, inTree)\n",
    "        # 更新相应频繁项集的链表，往后添加\n",
    "        if headerTable[items[0]][1] == None:\n",
    "            headerTable[items[0]][1] = inTree.children[items[0]]\n",
    "        else:\n",
    "            updateHeader(headerTable[items[0]][1], inTree.children[items[0]])\n",
    "    # 递归\n",
    "    if len(items) > 1:\n",
    "        updateFPtree(items[1::], inTree.children[items[0]], headerTable, count)\n",
    "\n",
    "def createFPtree(word_dict, cutted, minSup=1):\n",
    "    headerTable = {}\n",
    "    for trans in word_dict:\n",
    "        for item in trans:\n",
    "            headerTable[item] = headerTable.get(item, 0) + dataSet[trans]\n",
    "    freqItemSet = set(headerTable.keys()) # 满足最小支持度的频繁项集\n",
    "    if len(freqItemSet) == 0:\n",
    "        return None, None\n",
    "    for k in headerTable:\n",
    "        headerTable[k] = [headerTable[k], None] # element: [count, node]\n",
    "\n",
    "    retTree = treeNode('Null Set', 1, None)\n",
    "    for tranSet, count in dataSet.items():\n",
    "        # dataSet：[element, count]\n",
    "        localD = {}\n",
    "        for item in tranSet:\n",
    "            if item in freqItemSet: # 过滤，只取该样本中满足最小支持度的频繁项\n",
    "                localD[item] = headerTable[item][0] # element : count\n",
    "        if len(localD) > 0:\n",
    "            # 根据全局频数从大到小对单样本排序\n",
    "            orderedItem = [v[0] for v in localD.items()]\n",
    "            # 用过滤且排序后的样本更新树\n",
    "            updateFPtree(orderedItem, retTree, headerTable, count)\n",
    "    return retTree, headerTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "大乔/为/你/点赞\n"
     ]
    }
   ],
   "source": [
    "print (\"/\".join(jieba.cut(\"大乔为你点赞\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "大乔/为你点赞\n"
     ]
    }
   ],
   "source": [
    "jieba.add_word(\"大乔\", freq = 10000, tag = None)\n",
    "print (\"/\".join(jieba.cut(\"大乔为你点赞\")))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
