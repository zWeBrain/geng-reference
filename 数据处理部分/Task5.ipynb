{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import sys\n",
    "import math\n",
    "import heapq\n",
    "import shutil\n",
    "import queue as Q\n",
    "from nltk.stem import PorterStemmer \n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import jieba\n",
    "import nltk\n",
    "from model import TrieNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = os.path.exists('blocks')\n",
    "if not folder:\n",
    "    os.makedirs('blocks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_path = '动漫_简化'\n",
    "files= os.listdir(ori_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_union(d1, d2):\n",
    "    keys = d1.keys() | d2.keys()\n",
    "    temp = {}\n",
    "    for key in keys:\n",
    "        temp[key] = sum([d.get(key,0) for d in (d1, d2)])\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct1(intToJuji, intToFanju):\n",
    "    i = 0\n",
    "    j = -1000\n",
    "    k = 0\n",
    "    terms_id = dict()\n",
    "    for root, dirs, files in os.walk(ori_path, topdown=True):\n",
    "        if '\\.ipynb_checkpoints' in root:\n",
    "            continue\n",
    "        if len(files) == 0:\n",
    "            j+=1000\n",
    "            i=0\n",
    "            intToFanju[j] = root\n",
    "        else:\n",
    "            i+=1\n",
    "            key = j+i\n",
    "            intToJuji[key] = root\n",
    "            for name in files:\n",
    "                f = open(root+\"\\\\\"+ name, errors='ignore')\n",
    "                lines = f.readlines()\n",
    "                texts_s,texts_l = arrayTodict(lines)\n",
    "                counts = cut3(texts_s)\n",
    "            for word in counts:\n",
    "                terms_id[word] = terms_id.get(word, 0) + counts[word]\n",
    "    return terms_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct(intToJuji, intToFanju):\n",
    "    i = 0\n",
    "    j = -1000\n",
    "    k = 0\n",
    "    terms_id = dict()\n",
    "    for root, dirs, files in os.walk(ori_path, topdown=True):\n",
    "        if '\\.ipynb_checkpoints' in root:\n",
    "            continue\n",
    "        if len(files) == 0:\n",
    "            if j>0:\n",
    "                build_c(j, terms_id)\n",
    "                terms_id = dict()\n",
    "            j+=1000\n",
    "            i=0\n",
    "            intToFanju[j] = root\n",
    "        else:\n",
    "            i+=1\n",
    "            key = j+i\n",
    "            intToJuji[key] = root\n",
    "            counts = dict()\n",
    "            for name in files:\n",
    "                f = open(root+\"\\\\\"+ name, errors='ignore')\n",
    "                lines = f.readlines()\n",
    "                texts_l = arrayTodict(lines)\n",
    "                counts = dict_union(counts, cut1(texts_l))\n",
    "            for word in counts:\n",
    "                if word in terms_id:\n",
    "                    terms_id[word].append((key,counts[word]))\n",
    "                else: \n",
    "                    terms_id[word] = [(key,counts[word])]\n",
    "    build_c(j, terms_id)\n",
    "    terms_id = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "intToJuji = dict()\n",
    "intToFanju= dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intToFanju"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_words = construct(intToJuji, intToFanju)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_words = sorted(small_words.items(),key = lambda item: -item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51619"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_words = []\n",
    "for word in small_words:\n",
    "    if word[1]!=1:\n",
    "        new_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1678648"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(small_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'sjkk啥呀'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in superfluous:\n",
    "    s = s.rstrip(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sjkk'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shorten(s):\n",
    "    superfluous = ' 啊吧哇呀嘛吗耶？！?!.。诶了阿哈呗啥'\n",
    "    for i in superfluous:\n",
    "        s = s.rstrip(i)\n",
    "    ss= ''.join(reversed(s))\n",
    "    k = -1\n",
    "    j = 0\n",
    "    array = [-1]\n",
    "    plen = len(ss)\n",
    "    zeros = 0\n",
    "    nonze = 0\n",
    "    while j < plen:\n",
    "        if k == -1 or ss[j] == ss[k]:\n",
    "            k += 1\n",
    "            j += 1\n",
    "            if k == 0:\n",
    "                if j != zeros + 1:\n",
    "                    loop = (int)(nonze/zeros) -1\n",
    "                    return cut_string(s, plen) if loop<1 else cut_string(s, plen - zeros*loop)\n",
    "                zeros += 1\n",
    "            else:\n",
    "                nonze += 1\n",
    "            array.append(k)\n",
    "        else:\n",
    "            k = array[k]\n",
    "    return cut_string(s, plen) if zeros==plen else (cut_string(s, zeros) if zeros>1 else cut_string(s, zeros+1)) \n",
    "def cut_string(s, lens):\n",
    "    return s[0: lens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrayTodict(lines):\n",
    "    word_dict_s={}\n",
    "    word_dict_l={}\n",
    "    for line in lines:\n",
    "        line=shorten(line.strip('\\n').replace(' ', ''))\n",
    "        if len(line)<2:\n",
    "            continue\n",
    "        if len(line)<5:\n",
    "            if word_dict_s.get(line):\n",
    "                word_dict_s[line] += 1\n",
    "            else:\n",
    "                word_dict_s[line] = 1\n",
    "            continue\n",
    "        if word_dict_l.get(line):\n",
    "            word_dict_l[line] += 1\n",
    "        else:\n",
    "            word_dict_l[line] = 1\n",
    "    return word_dict_s, word_dict_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrayTodict(lines):\n",
    "    word_dict_l={}\n",
    "    for line in lines:\n",
    "        line=shorten(line.strip('\\n').replace(' ', ''))\n",
    "        if len(line)<2:\n",
    "            continue\n",
    "        if word_dict_l.get(line):\n",
    "            word_dict_l[line] += 1\n",
    "        else:\n",
    "            word_dict_l[line] = 1\n",
    "    return word_dict_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut1(word_dict):\n",
    "    counts = dict()\n",
    "    for line in word_dict:\n",
    "        num = word_dict[line]\n",
    "        words = jieba.lcut(line)\n",
    "        if len(words) > 5:\n",
    "            continue\n",
    "        for word in words:\n",
    "            if len(word) == 1:\n",
    "                continue\n",
    "            else:\n",
    "                counts[word] = counts.get(word, 0) + num\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut3(word_dict):\n",
    "    counts = dict()\n",
    "    for line in word_dict:\n",
    "        num = word_dict[line]\n",
    "        counts[line] = counts.get(line, 0) + num\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut2(word_dict):\n",
    "    counts = dict()\n",
    "    for line in word_dict:\n",
    "        num = word_dict[line]\n",
    "        if len(line)<5:\n",
    "            counts[line] = counts.get(line, 0) + num\n",
    "            continue\n",
    "        words = jieba.lcut(line)\n",
    "        for word in words:\n",
    "            if len(word) == 1:\n",
    "                continue\n",
    "            else:\n",
    "                counts[word] = counts.get(word, 0) + num\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_c(i, terms_id):\n",
    "    list1 = []\n",
    "    path = \"chunks/chunk_\"+str(i)+\".txt\"\n",
    "    list1 = sorted(terms_id.items(), key=lambda item: item[0])\n",
    "    with open(path, 'w', newline='') as f:\n",
    "        for key in list1:\n",
    "            list2= []\n",
    "            #cnt = 0\n",
    "            f.write(str(key[0]))\n",
    "            for word in key[1]:\n",
    "                f.write(',')\n",
    "                f.write(str(word[0]))\n",
    "                f.write('-')\n",
    "                #cnt += word[1]\n",
    "                f.write(str(word[1]))\n",
    "            #f.write(',')\n",
    "            #f.write(str(cnt))\n",
    "            f.write('\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dirs():\n",
    "    # Create a new folder to generate inverted indexes\n",
    "    folder1 = os.path.exists('chunks')\n",
    "    folder2 = os.path.exists('blocks')\n",
    "    if not folder1:\n",
    "        os.makedirs('chunks')\n",
    "    if not folder2:\n",
    "        os.makedirs('blocks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_dirs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'233'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shorten('2333')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'233'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shorten('23333333')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class treeNode:\n",
    "    def __init__(self, nameValue, numOccur, parentNode):\n",
    "        self.name = nameValue\n",
    "        self.count = numOccur\n",
    "        self.nodeLink = None\n",
    "        self.parent = parentNode\n",
    "        self.children = {}\n",
    "\n",
    "    def inc(self, numOccur):\n",
    "        self.count += numOccur\n",
    "\n",
    "    def disp(self, ind=1):\n",
    "        print ('  '*ind, self.name, ' ', self.count)\n",
    "        for child in self.children.values():\n",
    "            child.disp(ind+1)\n",
    "    def disp_plus(self, ind=1):\n",
    "        print ('  '*ind, self.name, ' ', self.count)\n",
    "        for child in self.children.values():\n",
    "            if child.count > 10:\n",
    "                child.disp_plus(ind+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateHeader(nodeToTest, targetNode):\n",
    "    while nodeToTest.nodeLink != None:\n",
    "        nodeToTest = nodeToTest.nodeLink\n",
    "    nodeToTest.nodeLink = targetNode\n",
    "def updateFPtree(items, inTree, headerTable, count):\n",
    "    if items[0] in inTree.children:\n",
    "        # 判断items的第一个结点是否已作为子结点\n",
    "        inTree.children[items[0]].inc(count)\n",
    "    else:\n",
    "        # 创建新的分支\n",
    "        inTree.children[items[0]] = treeNode(items[0], count, inTree)\n",
    "        # 更新相应频繁项集的链表，往后添加\n",
    "        if headerTable[items[0]][1] == None:\n",
    "            headerTable[items[0]][1] = inTree.children[items[0]]\n",
    "        else:\n",
    "            updateHeader(headerTable[items[0]][1], inTree.children[items[0]])\n",
    "    # 递归\n",
    "    if len(items) > 1:\n",
    "        updateFPtree(items[1::], inTree.children[items[0]], headerTable, count)\n",
    "\n",
    "def createFPtree(word_dict, cutted, minSup=1):\n",
    "    headerTable = {}\n",
    "    for trans in word_dict:\n",
    "        for item in trans:\n",
    "            headerTable[item] = headerTable.get(item, 0) + dataSet[trans]\n",
    "    freqItemSet = set(headerTable.keys()) # 满足最小支持度的频繁项集\n",
    "    if len(freqItemSet) == 0:\n",
    "        return None, None\n",
    "    for k in headerTable:\n",
    "        headerTable[k] = [headerTable[k], None] # element: [count, node]\n",
    "\n",
    "    retTree = treeNode('Null Set', 1, None)\n",
    "    for tranSet, count in dataSet.items():\n",
    "        # dataSet：[element, count]\n",
    "        localD = {}\n",
    "        for item in tranSet:\n",
    "            if item in freqItemSet: # 过滤，只取该样本中满足最小支持度的频繁项\n",
    "                localD[item] = headerTable[item][0] # element : count\n",
    "        if len(localD) > 0:\n",
    "            # 根据全局频数从大到小对单样本排序\n",
    "            orderedItem = [v[0] for v in localD.items()]\n",
    "            # 用过滤且排序后的样本更新树\n",
    "            updateFPtree(orderedItem, retTree, headerTable, count)\n",
    "    return retTree, headerTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "吉良吉影/觉得很赞\n"
     ]
    }
   ],
   "source": [
    "print (\"/\".join(jieba.cut(\"吉良吉影觉得很赞\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_words = []\n",
    "f = open(\"new_words_all.txt\")\n",
    "lines = f.readlines()\n",
    "for line in lines:\n",
    "    split = line.strip().split(',')\n",
    "    new_words.append((split[0],int(split[1])))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('233', 251716)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key_word in new_words:\n",
    "    if key_word[1] > 2:\n",
    "        jieba.add_word(key_word[0], freq = key_word[1]*10, tag = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_blocks_heap(N):\n",
    "    # SPIMI\n",
    "    reader = txt_reader('chunks')\n",
    "    heap = []\n",
    "    for i in range(len(reader)):\n",
    "        next_line = reader[i].readline().strip().split(',')\n",
    "        heapq.heappush(heap, (next_line[0], next_line[1:], i))\n",
    "    terms_id = dict()\n",
    "    j = 0\n",
    "    next_term = ''\n",
    "    try:\n",
    "        while not len(heap) == 0:\n",
    "            next_index = heapq.heappop(heap)\n",
    "            judge = (next_index[0] == next_term)\n",
    "            next_term = next_index[0]\n",
    "            next_line = reader[next_index[2]].readline()\n",
    "            if next_line:\n",
    "                next_line= next_line.strip().split(',')\n",
    "                heapq.heappush(heap, (next_line[0], next_line[1:], next_index[2]))\n",
    "            else:\n",
    "                reader[next_index[2]].close()\n",
    "            if (sys.getsizeof(terms_id) > 1000000 and not judge):\n",
    "                j = j + 1\n",
    "                build_b(j, terms_id, N)\n",
    "                terms_id = dict()\n",
    "            if next_term in terms_id:\n",
    "                terms_id[next_term].extend(next_index[1])\n",
    "            else: \n",
    "                terms_id[next_term] = next_index[1]\n",
    "    finally:\n",
    "        print(sys.getsizeof(terms_id))\n",
    "        j=j+1\n",
    "        build_b(j, terms_id, N)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'terms_id' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-112-162729b43154>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetsizeof\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mterms_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'terms_id' is not defined"
     ]
    }
   ],
   "source": [
    "sys.getsizeof(terms_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_b(i, terms_id, N):\n",
    "    path = \"blocks/block_\"+ str(i) +\".csv\"\n",
    "    with open(path, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        try:\n",
    "            for key in terms_id:\n",
    "                list2= []\n",
    "                list2.append(key)\n",
    "                idf = math.log(N /len(terms_id[key]), 10)\n",
    "                list2.append(idf)\n",
    "                list2.extend(terms_id[key])\n",
    "                writer.writerow(list2)\n",
    "        finally:\n",
    "            f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147560\n"
     ]
    }
   ],
   "source": [
    "build_blocks_heap(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(intToJuji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "894"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt_reader(path):\n",
    "    fileList = os.listdir(path)\n",
    "    files_reader = dict()\n",
    "    i = 0\n",
    "    for file in fileList:\n",
    "        if(file.split('.')[-1] == \"txt\"):\n",
    "            name = path+'/'+file\n",
    "            files_reader[i] = open(name, \"r\")\n",
    "            i = i + 1\n",
    "    return files_reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve(query, files_reader):\n",
    "    words = jieba.lcut(query)\n",
    "    query = []\n",
    "    for word in words:\n",
    "        query.append(word)\n",
    "    print(query)\n",
    "    format_query = dict()\n",
    "    D = len(query)\n",
    "    for word in query:\n",
    "        if word in format_query:\n",
    "            format_query[word] += 1\n",
    "        else:\n",
    "            format_query[word] = 1\n",
    "    scores = dict()\n",
    "    len1 = dict()\n",
    "    len2 = 0\n",
    "    for i in range(len(files_reader)):\n",
    "        with open(files_reader[i+1]) as f:\n",
    "            lines = csv.reader(f)\n",
    "            k = 0\n",
    "            for line in lines:\n",
    "                k+=1\n",
    "                if line[0] in format_query:\n",
    "                    idf1 = float(line[1])\n",
    "                    w2 = (1+math.log(int(format_query[line[0]]), 10)) * idf1\n",
    "                    for term in line[2:]:\n",
    "                        tmp = term.split('-')\n",
    "                        w1 = (1+math.log(int(tmp[1]), 10)) * idf1\n",
    "                        if tmp[0] in scores:\n",
    "                            scores[tmp[0]] += w1 * w2\n",
    "                        else: \n",
    "                            scores[tmp[0]] =  w1 * w2\n",
    "                            len1[tmp[0]] = 1\n",
    "                    len2 += w2 * w2\n",
    "        f.close()\n",
    "    for i in range(len(files_reader)):\n",
    "        with open(files_reader[i+1]) as f:\n",
    "            lines = csv.reader(f)\n",
    "            for line in lines:\n",
    "                for word in line[2:]:\n",
    "                    tmp = word.split('-')\n",
    "                    if tmp[0] in len1:\n",
    "                        w1 = (1+math.log(int(tmp[1]), 10)) * float(line[1])\n",
    "                        len1[tmp[0]] += w1 * w1\n",
    "        f.close()       \n",
    "    for score in scores:\n",
    "        scores[score] =scores[score] / math.sqrt(len1[score] * len2)\n",
    "    list1= sorted(scores.items(), key=lambda x:x[1], reverse=True)  \n",
    "    for answer in find_answer(list1, filename_index):\n",
    "        print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_answer(scores, filename_index):\n",
    "    answer = []\n",
    "    i = 0\n",
    "    for score in scores:\n",
    "        if i == 10:\n",
    "            return answer\n",
    "        i += 1\n",
    "        answer.append(filename_index[int(score[0])])\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'blocks'\n",
    "fileList = os.listdir(path)\n",
    "files_reader = dict()\n",
    "for file in fileList:\n",
    "    if(file.split('.')[-1] == \"csv\"):\n",
    "        name = path+'/'+file\n",
    "        com = re.compile(r\"_(\\d+).csv\", re.M)\n",
    "        find = com.findall(name)\n",
    "        i = int(find[0])\n",
    "        files_reader[i] = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['寄刀片']\n",
      "动漫_简化\\JOJO的奇妙冒险-黄金之风\\38_镇魂歌沉静地演奏着 其二\n",
      "动漫_简化\\辉夜大小姐想让我告白天才们的恋爱头脑战\\12_听不见烟花的声音后篇辉夜大小姐不想逃避\n",
      "动漫_简化\\JOJO的奇妙冒险黄金之风\\38_镇魂歌沉静地演奏着其二\n",
      "动漫_简化\\JOJO的奇妙冒险-黄金之风\\36_其名为迪亚波罗\n",
      "动漫_简化\\JOJO的奇妙冒险-星尘斗士-埃及篇\\22_迪奥的世界 其二\n",
      "动漫_简化\\JOJO的奇妙冒险\\20_西撒的孤独青春\n",
      "动漫_简化\\JOJO的奇妙冒险黄金之风\\31_总集篇JOJO的奇妙冒险黄金之风命运\n",
      "动漫_简化\\JOJO的奇妙冒险-黄金之风\\31_总集篇：JOJO的奇妙冒险 黄金之风 命运\n",
      "动漫_简化\\辉夜大小姐想让我告白天才们的恋爱头脑战\\11_早坂爱想泡澡藤原千花超想吃白银御行想见面听不见烟花的声音前篇\n",
      "动漫_简化\\JOJO的奇妙冒险-黄金之风\\30_在那看似即将坠落的天空下\n"
     ]
    }
   ],
   "source": [
    "solve('寄刀片', files_reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_index = intToJuji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "894"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(intToJuji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '动漫_简化',\n",
       " 1000: '动漫_简化\\\\AIR',\n",
       " 2000: '动漫_简化\\\\CLANNAD',\n",
       " 3000: '动漫_简化\\\\JOJO的奇妙冒险',\n",
       " 4000: '动漫_简化\\\\JOJO的奇妙冒险-不灭钻石',\n",
       " 5000: '动漫_简化\\\\JOJO的奇妙冒险-星尘斗士',\n",
       " 6000: '动漫_简化\\\\JOJO的奇妙冒险-星尘斗士-埃及篇',\n",
       " 7000: '动漫_简化\\\\JOJO的奇妙冒险-黄金之风',\n",
       " 8000: '动漫_简化\\\\JOJO的奇妙冒险黄金之风',\n",
       " 9000: '动漫_简化\\\\月色真美',\n",
       " 10000: '动漫_简化\\\\来自新世界',\n",
       " 11000: '动漫_简化\\\\游☆戏☆王5Ds第四季',\n",
       " 12000: '动漫_简化\\\\游☆戏☆王GX',\n",
       " 13000: '动漫_简化\\\\游戏王怪兽之决斗',\n",
       " 14000: '动漫_简化\\\\辉夜大小姐想让我告白天才们的恋爱头脑战',\n",
       " 15000: '动漫_简化\\\\高机动幻想GPO第二季',\n",
       " 16000: '动漫_简化\\\\高机动幻想～新结行军歌～',\n",
       " 17000: '动漫_简化\\\\高达创形者',\n",
       " 18000: '动漫_简化\\\\高达创形者再起',\n",
       " 19000: '动漫_简化\\\\高达创战者',\n",
       " 20000: '动漫_简化\\\\鬼灭之刃',\n",
       " 21000: '动漫_简化\\\\魔法少女小圆',\n",
       " 22000: '动漫_简化\\\\魔法纪录魔法少女小圆外传',\n",
       " 23000: '动漫_简化\\\\魔法记录-魔法少女小圆外传'}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intToFanju"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
